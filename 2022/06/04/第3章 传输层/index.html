<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon_32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon_16.png">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hdfzzf.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="个人的知识笔记。">
<meta property="og:type" content="article">
<meta property="og:title" content="第3章 传输层">
<meta property="og:url" content="https://hdfzzf.github.io/2022/06/04/%E7%AC%AC3%E7%AB%A0%20%E4%BC%A0%E8%BE%93%E5%B1%82/index.html">
<meta property="og:site_name" content="HDFZZF&#39;s BLOG">
<meta property="og:description" content="个人的知识笔记。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602230655.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602232405.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602232449.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602233129.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602232940.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603171648.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603195008.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603195424.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603202300.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603202315.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603203830.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603203842.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603205342.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603205402.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603205627.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603211049.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603211103.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603211130.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603211215.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603213128.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603213430.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603215455.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603220247.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603220515.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603221025.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603221524.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603222345.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603222423.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603222527.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603224648.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603225555.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603230219.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604084048.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604084108.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604085250.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604091000.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604090706.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604092407.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604093442.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604100105.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604100201.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604100401.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101748.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101811.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101847.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101314.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101512.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101926.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604102016.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604102304.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604102437.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604104220.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604105127.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604105041.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604111045.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604112929.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604112902.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604112735.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604113833.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604114804.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604120508.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604120704.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604135804.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604140043.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604140312.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604142205.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604142348.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604142828.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604142916.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604143647.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604144605.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604150112.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604182606.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604184512.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604190419.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604190756.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604193208.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604193323.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604194723.png">
<meta property="article:published_time" content="2022-06-03T16:00:00.000Z">
<meta property="article:modified_time" content="2022-06-05T12:37:44.991Z">
<meta property="article:author" content="hdfzzf">
<meta property="article:tag" content="计算机网络">
<meta property="article:tag" content="计算网络教程 自顶向下方法">
<meta property="article:tag" content="B站中科大计网">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602230655.png">


<link rel="canonical" href="https://hdfzzf.github.io/2022/06/04/%E7%AC%AC3%E7%AB%A0%20%E4%BC%A0%E8%BE%93%E5%B1%82/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://hdfzzf.github.io/2022/06/04/%E7%AC%AC3%E7%AB%A0%20%E4%BC%A0%E8%BE%93%E5%B1%82/","path":"2022/06/04/第3章 传输层/","title":"第3章 传输层"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>第3章 传输层 | HDFZZF's BLOG</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>
  <a target="_blank" rel="noopener" href="https://github.com/hdfzzf" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">HDFZZF's BLOG</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0%E5%92%8C%E4%BC%A0%E8%BE%93%E5%B1%82%E6%9C%8D%E5%8A%A1"><span class="nav-text">1. 概述和传输层服务</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E8%A7%A3%E5%A4%8D%E7%94%A8"><span class="nav-text">2. 多路复用、解复用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#tcp%E7%9A%84%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E8%A7%A3%E5%A4%8D%E7%94%A8"><span class="nav-text">2.1. TCP的多路复用&#x2F;解复用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8"><span class="nav-text">2.1.1. 多路复用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%B7%AF%E8%A7%A3%E5%A4%8D%E7%94%A8"><span class="nav-text">2.1.2. 多路解复用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#udp%E7%9A%84%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E8%A7%A3%E5%A4%8D%E7%94%A8"><span class="nav-text">2.2. UDP的多路复用&#x2F;解复用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-1"><span class="nav-text">2.2.1. 多路复用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%B7%AF%E8%A7%A3%E5%A4%8D%E7%94%A8-1"><span class="nav-text">2.2.2. 多路解复用</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%97%A0%E8%BF%9E%E6%8E%A5%E4%BC%A0%E8%BE%93udp"><span class="nav-text">3. 无连接传输：UDP</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#udp%E6%A0%A1%E9%AA%8C%E5%92%8Cchecksum"><span class="nav-text">3.1. UDP校验和(checksum)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86"><span class="nav-text">4. 可靠数据传输原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="nav-text">4.1. 问题描述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rdt%E7%9A%84%E5%8F%91%E5%B1%95"><span class="nav-text">4.2. RDT的发展</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#rdt-1.0-%E5%8F%AF%E9%9D%A0%E4%BF%A1%E9%81%93"><span class="nav-text">4.2.1. RDT 1.0 可靠信道</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rdt-2.0-%E6%AF%94%E7%89%B9%E5%B7%AE%E9%94%99%E7%9A%84%E4%BF%A1%E9%81%93"><span class="nav-text">4.2.2. RDT 2.0 比特差错的信道</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rdt-2.1-%E5%BC%95%E5%85%A5%E5%BA%8F%E5%8F%B7"><span class="nav-text">4.2.3. RDT 2.1 引入序号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rdt-2.2-%E6%97%A0nak%E7%9A%84%E5%8D%8F%E8%AE%AE"><span class="nav-text">4.2.4. RDT 2.2 无NAK的协议</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rdt-3.0-%E5%85%B7%E6%9C%89%E6%AF%94%E7%89%B9%E5%B7%AE%E9%94%99%E5%92%8C%E5%88%86%E7%BB%84%E4%B8%A2%E5%A4%B1%E7%9A%84%E4%BF%A1%E9%81%93"><span class="nav-text">4.2.5. RDT 3.0 具有比特差错和分组丢失的信道</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#rdt-3.0-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">4.2.5.1. RDT 3.0 工作原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#rdt-3.0-%E7%9A%84%E6%80%A7%E8%83%BD"><span class="nav-text">4.2.5.2. RDT 3.0 的性能</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%81%E6%B0%B4%E7%BA%BFpipelined%E5%8D%8F%E8%AE%AE"><span class="nav-text">4.3. 流水线(pipelined)协议</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3sliede-window%E5%8D%8F%E8%AE%AE"><span class="nav-text">4.3.1. 滑动窗口(sliede window)协议</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E7%BC%93%E5%86%B2%E5%8C%BA%E5%92%8C%E5%8F%91%E9%80%81%E7%AA%97%E5%8F%A3"><span class="nav-text">4.3.1.1. 发送缓冲区和发送窗口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%A5%E6%94%B6%E7%BC%93%E5%86%B2%E5%8C%BA%E5%92%8C%E6%8E%A5%E6%94%B6%E7%AA%97%E5%8F%A3"><span class="nav-text">4.3.1.2. 接收缓冲区和接收窗口</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E9%80%80n%E6%AD%A5go-back-n-gbn%E5%8D%8F%E8%AE%AE"><span class="nav-text">4.3.2. 回退N步（Go Back N, GBN）协议</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%89%E6%8B%A9%E9%87%8D%E4%BC%A0selective-repeat-sr%E5%8D%8F%E8%AE%AE"><span class="nav-text">4.3.3. 选择重传(Selective Repeat, SR)协议</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-text">4.3.4. 总结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E4%BC%A0%E8%BE%93tcp"><span class="nav-text">5. 面向连接的传输：TCP</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0"><span class="nav-text">5.1. 概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tcp%E7%9A%84rtt%E5%92%8C%E8%B6%85%E6%97%B6"><span class="nav-text">5.2. TCP的RTT和超时</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93"><span class="nav-text">5.3. 可靠数据传输</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A7%E7%94%9Ftcp-ack%E7%9A%84%E5%BB%BA%E8%AE%AE"><span class="nav-text">5.3.1. 产生TCP ACK的建议</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0"><span class="nav-text">5.3.2. 快速重传</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6"><span class="nav-text">5.4. 流量控制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86"><span class="nav-text">5.5. 连接管理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9E%E6%8E%A5%E5%BB%BA%E7%AB%8B"><span class="nav-text">5.5.1. 连接建立</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C%E6%AC%A1%E6%8F%A1%E6%89%8B"><span class="nav-text">5.5.1.1. 二次握手</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B"><span class="nav-text">5.5.1.2. 三次握手</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9E%E6%8E%A5%E6%8B%86%E9%99%A4"><span class="nav-text">5.5.2. 连接拆除</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86"><span class="nav-text">6. 拥塞控制原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%A5%E5%A1%9E%E7%9A%84%E5%8E%9F%E5%9B%A0%E4%BB%A3%E4%BB%B7"><span class="nav-text">6.1. 拥塞的原因&#x2F;代价</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF1"><span class="nav-text">6.1.1. 场景1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF2"><span class="nav-text">6.1.2. 场景2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF3"><span class="nav-text">6.1.3. 场景3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF4"><span class="nav-text">6.1.4. 场景4</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-text">6.2. 拥塞控制的方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#tcp%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6"><span class="nav-text">7. TCP拥塞控制</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%A5%E5%A1%9E%E6%84%9F%E7%9F%A5"><span class="nav-text">7.1. 拥塞感知</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A7%E5%88%B6%E7%AD%96%E7%95%A5"><span class="nav-text">7.2. 控制策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%85%A2%E5%90%AF%E5%8A%A8%E9%98%B6%E6%AE%B5"><span class="nav-text">7.2.1. 慢启动阶段</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%A5%E5%A1%9E%E9%81%BF%E5%85%8D%E9%98%B6%E6%AE%B5"><span class="nav-text">7.2.2. 拥塞避免阶段</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%A4%E4%B8%AA%E9%98%B6%E6%AE%B5%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="nav-text">7.2.3. 两个阶段具体实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="nav-text">7.2.4. 总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tcp%E5%90%9E%E5%90%90%E9%87%8F"><span class="nav-text">7.3. TCP吞吐量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tcp%E5%85%AC%E5%B9%B3%E6%80%A7"><span class="nav-text">7.4. TCP公平性</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="hdfzzf"
      src="/images/zzf.jpg">
  <p class="site-author-name" itemprop="name">hdfzzf</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">121</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">194</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hdfzzf" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hdfzzf" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:dfhong1998@163.com" title="E-Mail → mailto:dfhong1998@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hdfzzf.github.io/2022/06/04/%E7%AC%AC3%E7%AB%A0%20%E4%BC%A0%E8%BE%93%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zzf.jpg">
      <meta itemprop="name" content="hdfzzf">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HDFZZF's BLOG">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第3章 传输层
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-04 00:00" itemprop="dateCreated datePublished" datetime="2022-06-04T00:00:00+08:00">2022-06-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-06-05 20:37" itemprop="dateModified" datetime="2022-06-05T20:37:44+08:00">2022-06-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">计算机基础</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">计算机网络</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2022/06/04/%E7%AC%AC3%E7%AB%A0%20%E4%BC%A0%E8%BE%93%E5%B1%82/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/06/04/第3章 传输层/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>21k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>19 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>个人的知识笔记。</p>
<span id="more"></span>
<h1 id="概述和传输层服务">1. 概述和传输层服务</h1>
<p><strong>传输层的作用</strong>：</p>
<ol type="1">
<li>为运行在不同主机上的应用进程提供<strong>逻辑通信</strong></li>
<li>传输层协议运行在端系统：
<ul>
<li>发送方：将应用层message划分成多个报文段（segment），然后向下传递给网络层</li>
<li>接收方：将segment重组成message，然后传递给应用层</li>
</ul></li>
<li>有两个传输层协议：
<ul>
<li>TCP</li>
<li>UDP</li>
</ul></li>
</ol>
<p><strong>传输层和网络层的区别</strong>：</p>
<ul>
<li>网络层：主机之间的逻辑通信</li>
<li>传输层：应用进程间的逻辑通信
<ul>
<li>依赖于网络层的服务</li>
<li>对网络层的服务进行加强：数据丢失、顺序混乱、加密(SSL)</li>
</ul></li>
</ul>
<p>有些服务是可以加强的，比如网络层的服务是不可靠的，通过传输层，可以向上提供可靠的服务；还可以使用SSL加强安全方面的功能；但是，还有些服务是无法通过传输层加强的，比如说带宽和时延。</p>
<p><strong>传输层的协议</strong>：</p>
<ol type="1">
<li>可靠的传输：TCP
<ul>
<li>多路复用、解复用</li>
<li>拥塞控制</li>
<li>流量控制</li>
<li>建立连接</li>
<li>向上层传输字节流</li>
</ul></li>
<li>不可靠的传输：UDP
<ul>
<li>多路复用、解复用</li>
<li>没有为尽力而为的IP服务添加其他额外的服务</li>
<li>向上层传输数据报</li>
</ul></li>
</ol>
<p><strong>两者也有其共同点</strong>：</p>
<ul>
<li>都不为上层提供<strong>时延保证</strong>；</li>
<li>都不为上层提供<strong>带宽保证</strong>；</li>
</ul>
<p><strong>数据报和字节流的区别？以及原因？</strong></p>
<p><strong>字节流</strong>：传输层向上层发送的数据是“流式的”，就是没有边界之分。假如应用进程发送了5个message，那么传输层向目标进程发送的就是这5个message的字节流，说白点就是一堆数据直接往上层发送，要想区分这5个message，上层的应用自己想办法。</p>
<p><strong>数据报</strong>：发送方发送多少，接收方的传输层就给上层发送多少数据。</p>
<p>因为TCP服务能够保证message的顺序，所以将message按照正确的先后顺序放到一起，形成字节流向上层传输，应用进程负责将字节流分割成原本的message。先读取第一个message的大小的字节，再读取第二个，依次类推，最终得到的就是有序的message。</p>
<p>而UDP提供不可靠的传输，因此不保证顺序。假设UDP也适用字节流，如果message按照1，2，3的顺序发送，但是由于路由、网络的问题，到达的顺序是2，1，3，UDP将这些message按照先后顺序直接堆在一起向上层传输，上层根据第1个message的大小读取，然后按照第2个message的大小读取，最后按照第3个message的大小读取。运气好点，三个message的大小一致，那么也只是顺序乱了。运气不好假设1是50bytes，2是10byte，3是40byte，那么由于达到的顺序是2，1，3，那么应用层先读取50byte的大小，此时得到的 1' 为原先2的10byte和原先1的前40byte的组合；得到的 2' 为原先1的后10个byte；3'和3还是一样的。</p>
<p>这就是为什么TCP使用字节流，而UDP采用数据报。</p>
<h1 id="多路复用解复用">2. 多路复用、解复用</h1>
<p>因为TCP上面可能运行则会许多应用进程，这么多进程通过不同的端口发送数据到TCP。TCP不在乎上层的进程，将message与相关信息组合成segment之后就往下发。这就叫做多路复用。对于TCP来说上层的进程是谁，用的什么协议它都不care。</p>
<p>多路解复用是多路复用的相反的过程。TCP收到segment之后需要将其正确的传输给上层的应用进程，但是它并不知道上层有哪些应用，只能够根据segment中的port向上层传数据。画个形象的图：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602230655.png" /></p>
<blockquote>
<p>UDP也有类似的过程</p>
</blockquote>
<h2 id="tcp的多路复用解复用">2.1. TCP的多路复用/解复用</h2>
<p>TCP在两个进程之间建立逻辑连接。一个进程的socket有：<code>socket, 源IP, 源port, 目标IP, 目标port, pid</code>。</p>
<h3 id="多路复用">2.1.1. 多路复用</h3>
<p>不同的进程通过不同的socket向TCP传递数据。TCP将源端口，目标端口和message封装成segment（如果数据太大，需要分成多个segment，这里为了简单，假设数据正好就是一个segment），然后把segment和源IP，目标IP向网络层传，接下来网络成会将segment和源、目标IP分装成packet继续往下。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602232405.png" /></p>
<h3 id="多路解复用">2.1.2. 多路解复用</h3>
<p>IP将packet中的头部去除，然后向上层传递，TCP从segment的头部中读取port，然后传递给对应的进程。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602232449.png" /></p>
<h2 id="udp的多路复用解复用">2.2. UDP的多路复用/解复用</h2>
<h3 id="多路复用-1">2.2.1. 多路复用</h3>
<p>UDP和TCP类似，只不过在多路复用时，应用层往传输层传递的信息多了一个：目标IP和目标port。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602233129.png" /></p>
<h3 id="多路解复用-1">2.2.2. 多路解复用</h3>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220602232940.png" /></p>
<h1 id="无连接传输udp">3. 无连接传输：UDP</h1>
<p><strong>UDP: User Datagram Protocol</strong></p>
<ul>
<li>提供不可靠的、尽力而为的服务
<ul>
<li>报文可能丢失</li>
<li>到达目标进程的报文顺序可能会打乱</li>
</ul></li>
<li>无连接
<ul>
<li>UDP发送方和接收方之间没有握手</li>
<li><strong>每个UDP报文段被独立处理</strong>（这与TCP的字节流是不一样的）</li>
</ul></li>
<li>UDP适用于：
<ul>
<li>流媒体</li>
<li>DNS</li>
<li>SNMP</li>
</ul></li>
</ul>
<p>如果想要在UDP上实现可靠的传输，有两种方案：</p>
<ul>
<li>在应用层增加可靠性</li>
<li>使用特定的差错恢复（UDP并没有差错恢复，只有差错检测）</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603171648.png" /></p>
<p><strong>为什么要有UDP？</strong></p>
<ol type="1">
<li>无连接。向DNS这样的就很适合</li>
<li>简单。发送方和接收方都没有连接状态</li>
<li>报文段的头部(head or cost)很小，只有8个字节</li>
<li>无拥塞控制和流量控制，使得UDP可以尽可能块的发送报文段
<ul>
<li>应用层给传输层的速率，会等于传输层往下传的速率，也会等于主机往网络里传数据的速率</li>
</ul></li>
</ol>
<h2 id="udp校验和checksum">3.1. UDP校验和(checksum)</h2>
<p><strong>UDP的差错检测：UDP校验和</strong>。</p>
<p>因为数据在网络中传输也有可能会因为链路质量问题、外界因素等原因使得某一些bit出现了差错。数据被路由器保存的时候也有可能会出现bit的差错。</p>
<p><strong>目标</strong>：检测在被传输报文段中的差错。</p>
<p>UDP的校验和需要计算<strong>UDP首部</strong>加<strong>数据荷载</strong>部分，但也需要加上<strong>UDP伪首部</strong>。这个伪首部指，源地址、目的地址、UDP数据长度、协议类型（0x11），协议类型就一个字节，但需要补一个字节的0x0，构成12个字节。伪首部+UDP首部+数据一起计算校验和。</p>
<p>UDP检验和的计算方法是：</p>
<ol type="1">
<li>将报文段每16bit分成一段。也就是报文段必须是16bit的整数，如果不够，需要在数据载荷后面填0补齐</li>
<li>取出第1，2个段，然后相加得到结果res1</li>
<li>将res1和第3个段相加，得到res2</li>
<li>依此类推，知道所有段都加完，得到最终的结果finRes</li>
<li>将 finRes 取反码。这就是UDP报文段的校验和，将其填入“校验和”字段</li>
</ol>
<p><strong>两个段相加可能会导致溢出，此时需要回卷</strong>。在接下来的例子中说明这一点。</p>
<p><strong>发送方</strong>：</p>
<p>举一个计算的例子，假设UDP报文段总共有48bits，一共将其分成三段：（这里左边为低位，右边为高位）</p>
<ul>
<li><code>1110011001100110</code></li>
<li><code>1101010101010101</code></li>
<li><code>0101010110101010</code></li>
</ul>
<p>首先 <span class="math inline">\(res1&#39;=1110011001100110+1101010101010101=11011101110111011\)</span>。注意 res1' 为17bit，超过16bit，这就是溢出，此时需要再次进行计算<span class="math inline">\(res1=1011101110111011+0000000000000001=1011101110111100\)</span>。</p>
<p>然后 <span class="math inline">\(finRes&#39;=res1+0101010110101010=10001000101100110\)</span>，因此，<span class="math inline">\(finRes=0001000101100111\)</span>。将finRes取反码（1变为0，0变为1），得到<span class="math inline">\(checksum=1110111010011000\)</span></p>
<p>最终，发送方发送的就是四段数据：</p>
<ul>
<li><code>1110011001100110</code></li>
<li><code>1101010101010101</code></li>
<li>`0101010110101010</li>
<li>checksum: <code>1110111010011000</code></li>
</ul>
<p><strong>接收方</strong>：</p>
<p>接收到这样的数据之后，将前三个字段进行一样的计算，然后与 checksum 做比较（或者这里可以将前3个段的计算结果与checksum相加，结果全为1表示相等，否则表示不相等）：</p>
<ul>
<li>如果相等：没有检测到差错（注意，是没有检测到，不代表没有）</li>
<li>如果不相等：检测到差错</li>
</ul>
<p>但是，UDP不提供差错恢复，因此即使检测到差错也只是向对应的应用进程发出警告。</p>
<p>这里最后解释一下为什么计算结果和 checksum 相等，也不代表没有差错。为了计算简单，就去两段数据：</p>
<ul>
<li><code>1110011001100110</code></li>
<li>`1101010101010101</li>
<li>chcksum: <code>0100010001000011</code></li>
</ul>
<p>接收方接收到下面的数据：</p>
<ul>
<li><code>0000000000001100</code></li>
<li><code>1011101110110000</code></li>
<li>checksum: <code>0100010001000011</code></li>
</ul>
<p>前两个段计算出的结果为：<code>1011101110111100</code> 取反得到 <code>0100010001000011</code>，与校验和一致，但此时接收的数据明显和发送的数据不一样。这就是为什么即使校验和通过，也无法保证没有差错，只是没有该机制无法检测出这种错误。</p>
<blockquote>
<p>端到端原则(end-end principle)：在某种功能必须基于端到端实现的情况下，“与在较高级别提供这些功能的代价相比，在较低级别上设置的功能可能是冗余的或几乎没有价值的”。</p>
</blockquote>
<p><strong>在这里，功能就是差错检测，要在较高级别实现，这就是UDP有差错检测的原因。</strong></p>
<h1 id="可靠数据传输原理">4. 可靠数据传输原理</h1>
<h2 id="问题描述">4.1. 问题描述</h2>
<ol type="1">
<li>Reliable Data Transfers, RDT: 可靠数据传输</li>
<li>Unreliable Data Transfers, UDT: 不可靠数据传输</li>
</ol>
<p>rdt在应用层、传输层和数据链路层都很重要，是网络 Top10 问题之一。</p>
<p><strong>信道的不可靠性决定了可靠数据传输协议的复杂性！！！</strong></p>
<p>因此，一般将情况分为以下两种：</p>
<ol type="1">
<li><p><strong>底层信道可靠</strong></p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603195008.png" /></p></li>
<li><p><strong>底层信道不可靠</strong></p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603195424.png" /></p></li>
</ol>
<p>可以看到，如果信道可靠，传输层甚至什么事都不用做（可靠方面的事），直接往应用层传数据即可。但是如果信道越不可靠，传输层的可靠服务传输协议就越复杂。</p>
<h2 id="rdt的发展">4.2. RDT的发展</h2>
<h3 id="rdt-1.0-可靠信道">4.2.1. RDT 1.0 可靠信道</h3>
<p>下层信道完全可靠：</p>
<ul>
<li>没有比特出错</li>
<li>没有分组丢失</li>
</ul>
<p>这种情况下，应用层向传输层提交数据，传输层封装一下直接往下层传送即可。同样的，接收方的传输层收到下层的数据，解封装之后往上层传就可以了。不需要做可靠性方面的工作。</p>
<p>很理想，现实生活中一般不可能。</p>
<h3 id="rdt-2.0-比特差错的信道">4.2.2. RDT 2.0 比特差错的信道</h3>
<p>下层的信道可能会出错：分组中的比特可能会翻转（1变0，0变1），但是分组不会丢失。</p>
<ul>
<li>用 checksum 检测</li>
</ul>
<p><strong>问题</strong>：之前也说明了 checksum 只能检测，不能恢复。</p>
<p><strong>解决</strong>：</p>
<ul>
<li><strong>确认(Ack)</strong>：接收方显式的告诉发送方分组已被正确接收（checksum通过）。发送方收到Ack后，发送下一个分组</li>
<li><strong>否定确定(NAK)</strong>：接收方显式的告诉发送方分组发生了差错。发送方收到NAK后，重传分组</li>
</ul>
<p>没有差错的情况下：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603202300.png" /></p>
<p>有差错的情况下：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603202315.png" /></p>
<p><strong>这就意味着，发送方需要保存已发送的分组的副本用于重传。</strong></p>
<p>这种情况看上去很完美，能够解决分组的差错恢复的问题，但是，实际上有一个很严重的缺陷。那就是，<strong>差错恢复依赖于Ack和NAK</strong>。在网络中传输的分组可能发生差错，那么Ack和NAK也可能发生差错。</p>
<p>如果接收方回复的Ack发生了差错，使得发送方不知道接收方的意思。此时发送方应该怎么做呢：</p>
<ul>
<li>重传。可能会重复</li>
<li>不重传。那么这个包接收方就收不到。接收方收不到这个包就无法向上层提供可靠服务。</li>
</ul>
<h3 id="rdt-2.1-引入序号">4.2.3. RDT 2.1 引入序号</h3>
<p>在2.0的基础之上，在每个分组中加入序号。如果ACK/NAK出错，发送方重传分组。接收方根据分组的序号来判断是否重复。</p>
<ul>
<li>如果接收方刚刚发送的是Ack，丢弃重传的分组</li>
<li>如果接收方刚刚发送的是NAK，则接收重传的分组</li>
</ul>
<p>Ack出错：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603203830.png" /></p>
<p>NAK出错：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603203842.png" /></p>
<blockquote>
<p>这种发送数据之后等到接收方确认，然后再次发送的协议称为<strong>停止等待协议(stop-and-wait)</strong></p>
</blockquote>
<p>这种情况下只需要1bit来代表序号就可以了。<strong>0表示重传分组，1表示新分组</strong>。如果收到的Ack/NAK出错，重传0号分组。</p>
<p>其实是这样的：</p>
<ul>
<li>发送方发送第一个分组，此时为1，接收方回一个Ack，但是出错了。</li>
<li>发送方重传分组，此时为0，接收方收到后，回一个Ack，此时没出错，但是会将该分组丢弃。</li>
</ul>
<p>也就是任何一个分组，第一次发送都是1号分组，重传才是0号分组。接收方收到0号回想“我刚刚收到了呀，怎么给我重传了，我丢弃该分组，并给发送方会Ack”</p>
<p>这种情况下，接收方并不知道发送方有没有收到Ack/NAK。只能够通过发送方下次发送的分组是0还是1才能够知道发送方到底收没收到。</p>
<h3 id="rdt-2.2-无nak的协议">4.2.4. RDT 2.2 无NAK的协议</h3>
<p><strong>思想：用前一个分组的正向确认来代替当前分组的反向确认</strong></p>
<ul>
<li>功能上与2.1相同，但是只使用Ack而放弃NAK。</li>
<li>接收方对<strong>最后</strong>正确解释的分组发Ack，以替代NAK
<ul>
<li>接收方在Ack中必须显式的包含正确接收分组的序号</li>
</ul></li>
<li>当收到重复的Ack时，发送方采取与收到NAK时相同的动作，重传当前分组</li>
<li>为后面的一次发送多个数据单位做一个准备：
<ol type="1">
<li>一次发送多个</li>
<li>每一个的应答如果都有Ack或者NAK，麻烦</li>
<li>用前一个分组的正向确认来代替当前分组的反向确认</li>
<li>确认信息减少一半（少了NAK），协议处理简单</li>
</ol></li>
</ul>
<p>没有出错的情况下：</p>
<ol type="1">
<li>S发送P1，接收方响应Ack1</li>
<li>S发送P2，接收方响应Ack2</li>
<li>...</li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603205342.png" /></p>
<p>分组出错的情况下：</p>
<ol type="1">
<li>发送方（S）发送分组1（P1），接收方（R）接收之后，回一个Ack1。</li>
<li>S收到 Ack1之后发送P2，假设P2出错了，接收方再回一个Ack1</li>
<li>S再次收到Ack1就会知道，P2出错了，所以会重传P2</li>
<li>...</li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603205402.png" /></p>
<p>Ack出错的情况下：</p>
<ol type="1">
<li>S发送P0，R收到了，回一个Ack0</li>
<li>但是Ack0出错了，变成了Ack0'，S不理解Ack0'的意思，就会重传P0</li>
<li>R再次收到P0，就会知道Ack0出错了，再次发送Ack0，并将本次接收的P0丢弃</li>
<li>...</li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603205627.png" /></p>
<h3 id="rdt-3.0-具有比特差错和分组丢失的信道">4.2.5. RDT 3.0 具有比特差错和分组丢失的信道</h3>
<h4 id="rdt-3.0-工作原理">4.2.5.1. RDT 3.0 工作原理</h4>
<p>这种情况下，底层信道除了之前描述的比特差错，还可能存在分组丢失的问题。如果遇到比特差错，用2.2解决就可以了，因此，这里只讨论关于分组丢失情况下的处理。</p>
<p><strong>问题描述</strong>：2.2的协议能否解决分组丢失的问题呢？答案是不能，S发送P1之后需要等待R的Ack1，但如果此时P1丢失了，R没收到就不会发送Ack1，会一直等待P1；同样的，S会一直等待Ack1，不会重传P1，这时就发生了死锁。</p>
<p><strong>解决办法</strong>：加入等待时间。发送方发送完分组之后等待一段<strong>合理的时间</strong>，再这段时间内没有收到Ack就默认为分组丢失，接下来就会重传分组。这样就能够解除死锁。即使可能存在Ack因为网络拥塞的问题，没有在等待时间内到达发送方，也当作丢失，该情况下接收方会丢弃重传的分组，并再次回Ack。</p>
<blockquote>
<p>合理的时间：可以根据概率论知识来设定，可以是自适应的，也可以是固定的值，但一定要比RTT大，否则Ack来不及。这不是重点。</p>
</blockquote>
<p>此时的协议已经是一个完备的协议了，可以解决比特差错和分组丢失两大问题：</p>
<ol type="1">
<li>校验和</li>
<li>序号</li>
<li>Ack</li>
<li>重传</li>
<li>等待时间（超时时间）</li>
</ol>
<p>没有分组丢失的情况：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603211049.png" /></p>
<p>分组丢失的情况：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603211103.png" /></p>
<p>Ack丢失的情况：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603211130.png" /></p>
<p>还有一种奇葩的情况，那就是设置的等待时间太短了，Ack到不了发送方</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603211215.png" /></p>
<p>最后一种情况称之为<strong>过早超时</strong>，虽然也能够正常工作，但是效率低，一半的分组和确认都是重复的。因此，设置一个合理的等待时间（超时时间）也是很重要的。</p>
<h4 id="rdt-3.0-的性能">4.2.5.2. RDT 3.0 的性能</h4>
<p>RDT 3.0 也是 stop-and-wait 的协议。这种协议可以工作，但是性能很差。如果链路的容量很大，但是一次只能发送一个分组，分组的大小又远小于链路容量，因此利用率就很低。</p>
<p>例：1Gbps的链路，15ms的端-端传播时延，分组的大小为1kB。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603213128.png" /></p>
<p>传输时延：<span class="math inline">\(t_{trans}=\frac LR=\frac{1kB}{1Gbps}=8us\)</span></p>
<p>RTT：<span class="math inline">\(RTT=2*15ms=30ms\)</span></p>
<p>总时延：<span class="math inline">\(t=RTT + t_{trans} = 30.008ms\)</span></p>
<p>利用率：<span class="math inline">\(p=\frac {传输时延}{总时延}= \frac {0.008}{30.008} = 0.027\%\)</span></p>
<p>吞吐量：<span class="math inline">\(吞吐量 = 0.027\% * 1Gbps = 270kbps\)</span></p>
<p>发送一个分组的传输时延只有8us，但是发送之后的30ms内都不能够发送分组，只能等待Ack，这样子的利用率太低了，连1%都没有。花着1Gbps的钱，只使用了270kbps的量，太亏了。</p>
<p><strong>瓶颈在于：网络协议限制了物理资源的利用。</strong></p>
<p>因此，可以使用<strong>流水线协议(pipelined)</strong>来提高链路利用率。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603213430.png" /></p>
<p>当 n 增加到一定值的时候，利用率就会到达100%，此时无法再通过增加n来提高利用率。瓶颈就从网络协议转移到了链路带宽。</p>
<h2 id="流水线pipelined协议">4.3. 流水线(pipelined)协议</h2>
<p>流水线：允许发送方在<strong>未得到对方确认</strong>的情况下一次发送多个分组。这就意味着：</p>
<ol type="1">
<li>必须增加序号的范围：使用多个bit表示分组的序号</li>
<li>发送方/接收方要有缓冲区
<ul>
<li>发送方缓冲：已发送、未得到的确认的分组，可能需要重传</li>
<li>接收方缓冲：上层应用取数据的速率 <span class="math inline">\(\neq\)</span> 本层接收数据的速率；接收到的分组可能乱序，需要进行排序（可靠）</li>
</ul></li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603215455.png" /></p>
<p>先介绍一个通用的协议：滑动窗口协议</p>
<h3 id="滑动窗口sliede-window协议">4.3.1. 滑动窗口(sliede window)协议</h3>
<ul>
<li>当sw的尺寸为1时 -&gt; stop-and-wait 协议</li>
<li>当sw的尺寸大于1时 -&gt; pipelined 协议</li>
</ul>
<h4 id="发送缓冲区和发送窗口">4.3.1.1. 发送缓冲区和发送窗口</h4>
<p><strong>发送缓冲区</strong>：</p>
<ul>
<li>形式：内存中的一个区域，落入缓冲区的分开可以发送</li>
<li>功能：用于存放已发送未得到确认的分组，或者可以发送但未发送的分组</li>
<li>必要性：需要重发时可以使用</li>
</ul>
<p>发送缓冲区的大小决定一次最多可以发送多少个未经确认的分组</p>
<p>发送缓冲区中的分组可以分为：</p>
<ul>
<li>未发送的分组：落入发送缓冲区的分组，可以连续发送出去</li>
<li>已发送，未确认的分组：只有得到确认之后，才能将这些分组从发送缓冲区中删除</li>
</ul>
<p><strong>发送窗口</strong>：</p>
<ul>
<li>发送缓冲区中的一个范围
<ul>
<li>那些已发送但未经确认分组的<strong>序号</strong>构成的空间。也有可能包含已确认的序号，但是后沿的第一个分组一定未确认</li>
</ul></li>
<li>发送窗口的最大值 <span class="math inline">\(\leq\)</span> 发送缓冲区的值</li>
<li>一开始：没有发送任何一个分组
<ul>
<li>后沿 = 前沿 （后沿：靠近序号小的边，前沿：靠近序号大的边）</li>
<li>前沿、后沿之间的分组序号的数量就是发送窗口的尺寸，最开始为0</li>
</ul></li>
<li>每发送一个分组，前沿前移一个单位</li>
</ul>
<p>举个例子：</p>
<ol type="1">
<li><p>刚开始的时候，发送缓冲区（绿色）中有0-4这5个分组，此时发送窗口为0</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603220247.png" /></p></li>
<li><p>0，1，2分组发送，但未经确认，此时发送缓冲区不变，发送窗口尺寸为3</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603220515.png" /></p></li>
<li><p>0，1分组得到确认，此时发送缓冲区可以删除0，1，并将5，6加入；发送窗口的后沿移动到2的左边，发送窗口尺寸为1</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603221025.png" /></p></li>
</ol>
<p>发送窗口的移动分为两种：</p>
<ul>
<li><strong>前沿移动</strong>：发送缓冲区中已发送，但未经确认的分组增加时，也就是分组发送的时候。需要注意的是，前沿移动的极限不会超过发送缓冲区。</li>
<li><strong>后沿移动</strong>：发送缓冲区的分组得到确认。需要注意的是，像上面例子中，如果2得到了确认，但是0，1没有得到确认，那么后沿也不会移动！也就是需要发送缓冲区中，序号最小的分组得到了确认，后沿才可以移动。极限不能超过前沿</li>
</ul>
<p>上面的例子中的第3步就是后沿移动，这里再站是一个前沿移动的例子：紧接着上面例子的第3步，3，4，5分组被发送，但还未得到确认，此时前沿移动，结果如下：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603221524.png" /></p>
<h4 id="接收缓冲区和接收窗口">4.3.1.2. 接收缓冲区和接收窗口</h4>
<p><strong>接收窗口(Receiving Window, RW) <span class="math inline">\(=\)</span> 接收缓冲区</strong>。</p>
<blockquote>
<p>上层应用从中取数据，下层往里面灌数据。后面假设一旦接收窗口中的数据可以可靠的向上层提供，就会直接提供，同时接收窗口移动。</p>
</blockquote>
<p>接收窗口的作用：</p>
<ul>
<li>用于控制那些分组可以接收：
<ul>
<li>只有分组的序号落入接收窗口的分组才允许被接收</li>
<li>若序号在接收窗口之外，则丢弃</li>
</ul></li>
<li>接收窗口尺寸为1时，只能是顺序接收。因为序号是有序的，而接收窗口只有一个值，只能够接受完前一个才能接收后一个</li>
<li>接收窗口尺寸大于1时，可以乱序接收。假设接收窗口内的序号为1，2，3，可以接收2，3，1
<ul>
<li>乱序接收，但提交给上层的时候需要按序：1，2，3</li>
</ul></li>
</ul>
<p><strong>接收窗口的滑动和发送确认</strong>：</p>
<ul>
<li>滑动：
<ul>
<li>低序号的分组到来，接收窗口移动</li>
<li>高序号分组乱序到，缓存分组到不交付给上层，接收窗口不滑动</li>
</ul></li>
<li>发送确认：
<ul>
<li>接收窗口尺寸为1：发送连续收到的最大的分组确认（累计确认）。GBN使用</li>
<li>接收窗口尺寸大于1：收到哪个分组，只发送对用分组的确认（非累计确认，or 独立确认）。SR使用</li>
</ul></li>
</ul>
<p>接收窗口就没有发送窗口那样的前沿和后沿的了。接收窗口的尺寸只能是一个固定值，要移动就只能整个窗口移动。</p>
<p>举个例子：</p>
<ol type="1">
<li><p>刚开始的时候，接收窗口如下</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603222345.png" /></p></li>
<li><p>收到1，2分组，并发送Ack之后的结果</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603222423.png" /></p></li>
<li><p>当收到0分组的时候，接收窗口移动</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603222527.png" /></p></li>
</ol>
<p>之后，就可以接收3，4，5，6的分组了。</p>
<blockquote>
<p>接收方：红色的表示已收到，绿色的表示接收窗口；发送方：红色的表示发送窗口，绿色表示发送缓冲区</p>
</blockquote>
<p><strong>正常情况下，2个窗口的互动</strong>：</p>
<p>发送窗口：</p>
<ul>
<li>有新的分组落入发送缓冲区范围，发送，前沿移动</li>
<li>来了老的低序号分组的确认，后沿向前移动，新的分组落入发送缓冲区的范围</li>
</ul>
<p>接收窗口：</p>
<ul>
<li>收到分组，落入到接收窗口范围内，接收</li>
<li>是低序号分组，发送确认给对方</li>
</ul>
<p>在滑动窗口协议的基础之上，衍生了两个流水线协议：</p>
<ol type="1">
<li>回退N步协议</li>
<li>选择重传协议</li>
</ol>
<p>两者的最大区别在于接收窗口的尺寸：</p>
<ol type="1">
<li>GBN：接收窗口尺寸为1</li>
<li>SR：接收窗口尺寸大于1</li>
</ol>
<p>两者的共同之处：</p>
<ul>
<li>发送窗口尺寸都大于1</li>
<li>都能一次发送多个未经确认的分组</li>
</ul>
<h3 id="回退n步go-back-n-gbn协议">4.3.2. 回退N步（Go Back N, GBN）协议</h3>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603224648.png" /></p>
<ol type="1">
<li>上图中（发送缓冲区为4，接收窗口尺寸为1）可以看到，发送方发送了0，1，2，3，4四个分组，其中0，1被接收，2丢失，3到达了接收方。</li>
<li>0，1按顺序到达接收方，因此接收窗口移动，但是2丢失了，3到达接收方由于超出了接收窗口的范围，因此接收方回复一个Ack1，表示“我只接收到了0，1”。</li>
<li>发送方收到了来自0，1分组的确认，发送窗口后沿前移，发送缓冲区将0，1，删除，将4，5加入，并且发送4，5分组。</li>
<li>接收方收到4，5分组，但由于还是在接收窗口范围之外，所以回复的还是Ack1。</li>
<li>发送方在超时时间过后或者收到接收方的Ack1之后，会选择将2，3，4，5分组都重传。</li>
<li>最后，接收方按顺序接收了2，3，4分组。</li>
</ol>
<p>从上面可以看到，即使接收方接收到了3，4，5，但因为2没收到，所以发送的是Ack1，由于是累计确认，表达的意思就是“1以及之前的分组我都收到了，后面的分组我都没收到”。发送方接收到Ack1就会将2，3，4，5重传。</p>
<h3 id="选择重传selective-repeat-sr协议">4.3.3. 选择重传(Selective Repeat, SR)协议</h3>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603225555.png" /></p>
<ol type="1">
<li>上图中，发送方发送了0，接收方收到，接收窗口移动，发送Ack0</li>
<li>发送方发送1，接收方收到，接收窗口移动，发送Ack1</li>
<li>发送方发送2，分组丢失</li>
<li>发送方发送3，此时发送窗口满。接收方收到，接收窗口不移动，因为还没收到2。发送Ack3</li>
<li>发送方收到Ack0，发送窗口后沿移动，发送缓冲区删除0，添加4，并发送4。接收方收到4，接收窗口不移动，回复Ack4</li>
<li>发送方收到Ack1，发送窗口后沿移动，发送缓冲区删除1，添加5，并发送5。接收方收到4，接收窗口不移动，回复Ack5</li>
<li>分组2超时时间过，发送方重传，接收方收到，接收窗口移动，变为6，7，8，9。回复Ack2</li>
</ol>
<p>SR是非累计确认，只要分组序号在接收窗口内就会保存分组，并且会一个Ack，这个Ack仅仅代表“我收到了这个分组”，不能够表示收到这个分组序号之前的所有分组。发送方只对那些没有收到Ack的分组进行重发-<strong>选择性重发</strong>。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220603230219.png" /></p>
<h3 id="总结">4.3.4. 总结</h3>
<p><strong>GBN</strong>：</p>
<ul>
<li>发送端最多再、在流水线中有N个未确认的分组</li>
<li>接收端只是发送累积确认</li>
<li><strong>发送端拥有对最老的（最早发送的）未确认分组的定时器（超时定时器）</strong>
<ul>
<li>只需设置一个定时器</li>
<li>当定时器到时，重传所有未确认分组</li>
<li>当收到Ack，且此时还有已发送、未确认的分组，定时器重启</li>
<li>当收到Ack，此时没有已发送、未确认的分组，定时器关闭</li>
</ul></li>
</ul>
<p><strong>SR</strong>：</p>
<ul>
<li>发送端最多再、在流水线中有N个未确认的分组</li>
<li>接收方对每个到了的分组单独确认</li>
<li>发送方为每个未确认的分组保持一个定时器（超时定时器）
<ul>
<li>当定时器到时，只是重发到时的未确认分组</li>
<li>当分组的单确认，关闭对应分组的定时器</li>
</ul></li>
</ul>
<p><strong>到此为止，可靠数据传输拥有以下机制</strong>：</p>
<ol type="1">
<li>校验和</li>
<li>定时器</li>
<li>序号</li>
<li>Ack</li>
<li>窗口</li>
<li>流水线</li>
<li>重传</li>
</ol>
<h1 id="面向连接的传输tcp">5. 面向连接的传输：TCP</h1>
<h2 id="概述">5.1. 概述</h2>
<ul>
<li><p>点对点：一个发送方，一个接收方</p></li>
<li><p>可靠的、按顺序的字节流：没有报文边界</p></li>
<li><p>管道化（流水线）：TCP拥塞控制和流量控制设置窗口大小</p></li>
<li><p>发送和接收缓存</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604084048.png" /></p></li>
<li><p>全双工数据</p>
<ul>
<li>在同一连接中数据流双向流动</li>
<li>MSS：MAximum Segment Size，最大报文段长度</li>
</ul></li>
<li><p>面向连接：在数据交换之前，通过握手初始化双方的状态变量</p></li>
<li><p>有流量控制：发送方不会淹没接收方</p></li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604084108.png" /></p>
<p>上图中，除了 “应用层数据(或者叫body)” 之外，其他的都是头部。这里主要解释两个字段：序号和确认号。R, S, F是TCP连接建立、拆除时使用的</p>
<ul>
<li>序号：报文段的body部分的首字节在自己流中的偏移量</li>
<li>确认号：期望从另一发收到的下一个字节的偏移量；确认确认好之前的所有字节已成功接收（不包括确认号本身）</li>
<li>首部长度：主要用来指名该报文段中的首部的长度，用以区分首部和body</li>
</ul>
<p>解释一下（TCP为例），数据链路层帧的body部分最大长度为1500B，称为最大传输单元(Maximum transmission Unit, MTU)。也就是网络层的body部分加上IP头部（20字节）最大只能是1500字节。从而网络层的body最大为1480。同样的，网络层的body就是传输层的body加上TCP头部（一般为20字节，可能有可选项），因此，TCP报文段的最大长度就是1460字节，这个也称为<strong>最大报文段长度(Maximum Segment Size, MSS)</strong>。</p>
<p>应用层向下层传递的是字节流，假设传递了一个7300B的字节流，那么这个字节流会被划分为5段，每段的长度正好是MSS，需要为每一个MSS加上TCP首部字段。假设字节流的第一个字节的序号为x，那么第一个TCP报文段中的序号就是x，第二个TCP报文段中的序号就是x+MSS，依此类推。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604085250.png" /></p>
<p>当接收方收到第一个TCP报文段之后回复的确认号是 x+MSS，说明 x+MSS-1 及之前的都收到了，接下来请发送 x+MSS 开始的字节。（类似于累计确认）</p>
<blockquote>
<p><strong>TCP建立连接的时候会商量好对方的第一个字节的序号</strong>。所以，TCP字节流的第一个字节的序号一般不为0。这么做的好处就是古老的TCP报文段不会对现有的TCP报文产生影响。如果从0开始，很久之前的序号为0的报文段因为网络原因到达对方，但是现在的序号为0的报文段还没到达，如果新旧的进程连接使用的是同一端口，那么可能就会产生误会。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604091000.png" /></p>
<p>（TCP连接协商：A的第一个字节序号为42，B的第一个字节序号为79）</p>
<p>这里还需要说明一点，TCP中的接收窗口一般大于1，按照[[#4 3 1 2 接收缓冲区和接收窗口]]中的说法，此时应该采用非累计确认。但是，TCP采用了累计确认，那么就会出现一个问题</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604090706.png" /></p>
<p>上图中，每种颜色的字节为一个TCP报文段，如果此时接收到了蓝色的TCP报文段，应该怎么做？因为黄色的TCP报文段还没有收到，TCP无法回复Ack，这时有两种做法：</p>
<ol type="1">
<li>缓存蓝色TCP报文段，发送黄色第一个字节的Ack</li>
<li>直接丢弃蓝色TCP报文段</li>
</ol>
<p>这两种使用哪一种，协议没有明确指定，由厂家决定生产的产品要使用哪一种。</p>
<h2 id="tcp的rtt和超时">5.2. TCP的RTT和超时</h2>
<p>之前也说过，设置一个合理的超时时间是非常重要的。</p>
<ul>
<li>比RTT长，但是RTT一般是变化的</li>
<li>不能太短，否则会太早超时，发送一些不必要的重传</li>
<li>不能太长，否则报文丢失的时候，反应太慢，太消极</li>
</ul>
<p>因此，这里介绍一个种办法：</p>
<ol type="1">
<li>估计RTT
<ol type="1">
<li>sanmpleRTT：测量从报文段发出到收到确认的时间，如果有重传，则忽略此次测量</li>
<li>sampleRTT会变化，因此，对几个最近的测量值加权平均，得到的值作为RTT</li>
</ol></li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604092407.png" /></p>
<p>公式：</p>
<p><span class="math display">\[
estimatedRTT=(1-\alpha)*estimatedRTT + \alpha * sampleRTT
\]</span> 右边的 estimatedRTT 表示的是之前的RTT，左边的RTT表示的是当前的RTT。这是一个迭代的公式，将其展开就是：</p>
<p><span class="math display">\[
estimatedRTT = \alpha * sampleRTT_{Now} + (1-\alpha)*sampleRTT_{pre1}+(1-\alpha)^2*sampleRTT_{pre2}+...+(1-\alpha)^n*sampleRTT_{pre n}
\]</span></p>
<ol start="2" type="1">
<li>安全边界</li>
</ol>
<p>这一次的sampleRTT可能会与上一次的estimatedRTT相差很大，也可能相差很小。如果相差很大的话，说明estimatedRTT变化很大，此时方差很大，所以需要设置较大的安全边界时间，公式如下</p>
<p><span class="math display">\[
DevRTT=(1-\beta)*DevRTT+\beta * |sampleRTT-estimatedRTT|
\]</span></p>
<p>这也是一个迭代的式子。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604093442.png" /></p>
<ol start="3" type="1">
<li>设置超时时间。公式：</li>
</ol>
<p><span class="math display">\[
TimeoutInterval = estimatedRTT + 4 * DevRTT
\]</span></p>
<h2 id="可靠数据传输">5.3. 可靠数据传输</h2>
<p>TCP在IP不可靠服务的基础上，建立了RDT：</p>
<ul>
<li>管道化的报文段</li>
<li>累计确认（像GBN）</li>
<li>单个重传定时器（像GBN）</li>
<li>是否可以接收乱序TCP报文段，协议没有规定</li>
</ul>
<p><strong>TCP重传</strong>：</p>
<ol type="1">
<li>超时重传：只重传最早的未确认的TCP报文段（像SR）</li>
<li>快速重传：如果发送方连续收到多个同一个确认号的Ack，则重传该序号的TCP报文段</li>
</ol>
<ul>
<li>Ack丢失的情况：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604100105.png" /></p>
<ul>
<li>过早超时的情况：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604100201.png" /></p>
<p>虽然Ack超时了，但是接收方还是接收了92-99和110-119的字节，所以接收方再次收到 92-99 的TCP报文段的时候，发送的Ack还是120。</p>
<ul>
<li>累计确认：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604100401.png" /></p>
<p>这种情况和上一种情况类似，这里是Ack丢失，本质上也是发送方没有即使接收到Ack。</p>
<h3 id="产生tcp-ack的建议">5.3.1. 产生TCP ACK的建议</h3>
<p>这里介绍一下接收方在不同情况下会如何发送ACK。</p>
<ol type="1">
<li>期望的报文段按序到达，所有在期望的报文段之前的数据都已被确认</li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101748.png" /></p>
<p>黄色之前的都已经到达了，此时黄色的也到达。那么<strong>接收方不会直接发Ack</strong>，它会启动一个辅助定时器（500ms）。如果下一个报文段（蓝色）在这个时间段内没有到达，那么就会发送<strong>关于黄色的Ack</strong>。然后接收窗口移动</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101811.png" /></p>
<p>（红+绿为棕）</p>
<ol start="2" type="1">
<li>在上一种情况下，蓝色的报文段在规定时间内到达</li>
</ol>
<p>接收方接收蓝色报文段，并回复一个累计的Ack，确认两个报文段都到达了。接收窗口移动</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101847.png" /></p>
<ol start="3" type="1">
<li>比期望序号大的报文段乱序到达。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101314.png" /></p>
<p>期望黄色的，但是此时到来了棕色的，那么接收方会立即发送一个<strong>期待黄色报文段的Ack</strong>，指名下一个期待的报文段是黄色。至于棕色是缓存还是丢弃，由厂家决定。接收窗口不移动</p>
<ol start="4" type="1">
<li>能部分或完全填充接收数据间隔的报文段到达。
<ul>
<li>部分填充</li>
<li>完全填充</li>
</ul></li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101512.png" /></p>
<p>假设黑色和棕色已经接收，此时到来了黄色，那么接收方会发送<strong>期待蓝色的Ack</strong>。同时，接收窗口移动</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604101926.png" /></p>
<p>这种情况就是部分填充。</p>
<p>假设黑色和棕色已经接收，此时黄色和蓝色都来了，那么接收方就会发送<strong>期待白色的Ack</strong>。同时，接收窗口移动</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604102016.png" /></p>
<p>这种情况称为完全填充。</p>
<h3 id="快速重传">5.3.2. 快速重传</h3>
<p>因为超时时间的设置比较保守，因此超时周期往往比较长。因此，可以使用重复的Ack来检测报文段的丢失，从而实现快速重传</p>
<ul>
<li>发送方通常连续发送大量的报文段</li>
<li>如果中间某个报文段丢失，通常会引起多个重复的Ack（上面[[#产生TCP ACK的建议]]的第3种情况）</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604102304.png" /></p>
<p>像上图一样，发送方收到50-59这个同一数据的3个冗余的Ack（后面三个Ack），那么即使超时时间还没到，也会启动重传，此时重传的就是50-59，也就是<strong>最小的、未确认的序号的段</strong>。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604102437.png" /></p>
<h2 id="流量控制">5.4. 流量控制</h2>
<p>首先需要明确一定，TCP连接的两端，并不是一个是发送方，另一个是接收方，而是两端都是既为发送方也为接收方。</p>
<p>刚刚上面的描述中都只讨论了单向的数据传输，接收方只需要回Ack就可以了。实际并不是这样的。实际可能是，A发送一个TCP报文段，这个报文段内即存在要发送给B的数据，也存在着对B上一次发送的数据的确认。B收到A的TCP报文段后，如果自己还有数据没发，那么就会发送给A一个TCP报文段，里面包含了对此次A的报文段的确认，也包含了自己要发的数据。</p>
<p>如果B没有数据要发，那么TCP报文段内的body部分需要填充（帧也有一个最小的长度）</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604104220.png" /></p>
<blockquote>
<p>ack=0 表示之前并未接收到对方的报文段。我个人理解，书本没有提到</p>
</blockquote>
<p><strong>流量控制的目标</strong>：接收方控制发送方，不要发送的太快、太多，否则接收方的缓冲区会溢出。</p>
<p><strong>操作</strong>：</p>
<ul>
<li>接收方会在发送给发送方的TCP报文段头部的rwnd字段表明空闲的buffer的大小。</li>
<li>发送方限制未确认字节的个数 <span class="math inline">\(\leq\)</span> 接收方的rwnd值。如果大于，即使发送了也会被丢弃。</li>
<li>保证接收方不会被淹没</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604105127.png" /></p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604105041.png" /></p>
<blockquote>
<p>这里的RcvBuffer和之前提到的接收缓冲区是不一样的。接收缓冲区 = 接收窗口 = <span class="math inline">\(RcvBuffer - (lastByteRcvd - LastByteRead)\)</span></p>
</blockquote>
<h2 id="连接管理">5.5. 连接管理</h2>
<p>主要介绍：</p>
<ul>
<li>连接建立</li>
<li>连接拆除</li>
</ul>
<h3 id="连接建立">5.5.1. 连接建立</h3>
<p><strong>连接建立的本质</strong>：</p>
<ul>
<li>双方知道与对方通信</li>
<li>一些资源要准备好。比如说发送/接收缓冲区</li>
<li>一些控制变量要设置好。比如说序号</li>
</ul>
<h4 id="二次握手">5.5.1.1. 二次握手</h4>
<p>比较容易让人想到的建立过程就是，客户端发请求，服务器同意。那么TCP连接就建立起来了。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604111045.png" /></p>
<p>理想情况下是可行的，但是实际情况太复杂了。2次握手会有两个比较大的问题：</p>
<ol type="1">
<li>半连接</li>
<li>老的数据被当成新的数据接受了</li>
</ol>
<p>首先半连接：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604112929.png" /></p>
<p>客户发送的请求，服务器接收到了，服务器认为连接建立。但是回复的resp由于网络原因超时了，客户会再次发送req，过了一会，第一个req的resp到达，客户也认为连接建立。进行数据传输之后，连接断开，这时候之前重传的req到达，服务器认为客户再次请求连接，于是再次回复resp，但是客户端不理解这个resp的意思，因此客户端不建立此次连接。最终服务端维持了一个<strong>半连接</strong>，就是自己单方面认为的连接。</p>
<p><strong>连接需要使用资源的，半连接就相当于占了资源不干事。</strong></p>
<p>然后是第二个问题：老的数据被当成新的数据接受了</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604112902.png" /></p>
<p>第一次连接resp超时到达，所以重传了req。但是第一次连接双方还是建立起来了。愉快的传数据，（第一个数据重传了一次）然后连接断开。这个时候，重传的req到达，服务器再次建立连接（半连接），并且之前重传的数据也正好到了（并且还是正好的第一个数据），那么服务器会将该数据接收。</p>
<p>其实这里，除了半连接之外，服务器还接收了之前的数据，这是没有意义的。也白白占用了资源。</p>
<p>解决这两个问题的办法就是3次连接</p>
<h4 id="三次握手">5.5.1.2. 三次握手</h4>
<p>三次握手本质上是：</p>
<ol type="1">
<li>A：我的条件是这样</li>
<li>B：我同意</li>
<li>B：我的条件是这样</li>
<li>A：我也同意</li>
</ol>
<p>之后两者建立连接。但是刚刚也介绍过了，Ack可以和数据放到同一个TCP报文段中，因此简化为：</p>
<ol type="1">
<li>A：我的条件是这样</li>
<li>B：我同意。我的条件是这样</li>
<li>A：我也同意</li>
</ol>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604112735.png" /></p>
<p>（第三次握手可以带上数据）</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604113833.png" /></p>
<p>上图是半连接的情况，此时即使服务器收到重传的请求，并且接受了，回一个响应。客户不理解这个响应就拒绝了。连接建立不起来。服务器过了一段时间后没收到第三次握手，回到listen状态。</p>
<p>至于接收老数据，这个问题其实是建立在半连接之上的，而三次握手解决了半连接，因此自然而然的也解决了这个问题。</p>
<p>至于为什么不能使用固定的序号，比如从0开始。举个例子，假设序号从0开始，建立连接的过程就开始</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604114804.png" /></p>
<p>第一次TCP中，有一个数据重传了，在第2次TCP中，到达了，此时就会被服务器给错误的接收。虽然这几率不算很大，但也绝对不小（计算机中数据量太大了）。此时的概率为“前面的TCP连接数据i重传，正好在当前的TCP连接的数据i时到达”，为了降低概率，采用了随机的序号，在TCP建立的时候要协商好。</p>
<p>虽然，第一次TCP协商的和第二次协商的有可能一样，这个概率不算大，也不算小，但是这个概率只是前后TCP连接序号的起始是一样的概率，还要乘以“前面的TCP连接数据i重传，正好在当前的TCP连接的数据i时到达”的概率。两者相乘的概率就很小了，但不代表没有。</p>
<h3 id="连接拆除">5.5.2. 连接拆除</h3>
<p>TCP连接的拆除可以认为是拆除两个<strong>半连接</strong>。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604120508.png" /></p>
<p><strong>客户端</strong>：发送Fin，服务器收到之后，回一个Ack。此时客户端就不能往服务器发送数据。客户端这一侧的<strong>半连接</strong>被关闭</p>
<p><strong>服务器</strong>：也是一样的，服务器发送Fin，客户端收到之后，回一个Ack。此时服务器就不能往客户端发送数据，服务器这一侧的<strong>半连接</strong>被关闭。</p>
<p>特点是：</p>
<ul>
<li>对称释放</li>
<li>并不完美</li>
</ul>
<p>如何理解并不完美呢？这里介绍一个经典的问题“两军问题”，如下图</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604120704.png" /></p>
<p>此时，山谷两边的红军单挑是打不过白军的，但是如果两边的红军一起进攻，是可以打败蓝军。现在问题是，左边的红军如何与右边的红军协商好一个时间一起进攻呢？</p>
<p>左边派出一个人，从谷底绕过去，到达右边，然后告诉对方，明天8点进攻(Fin)。且不说这个人能不能到达，假设能够到达，左边的红军明天8点敢进攻吗？答案是不敢，因为不知道右边到底收没收到。</p>
<p>因此，右边收到消息之后需要也派一个人到达左边，告诉左边的红军，可以(Ack)。我们也不讨论这个人能否到达，假设这个人能到达。左边的红军这回敢进攻了，但是右边敢吗？他不敢呀，因为他不知道左边的红军能不能收到消息。</p>
<p>那么左边又要再派出一个人，然后右边收到后再派出一个人，没完没了了。这就是“两军问题”。在TCP连接拆除时也存在该问题。</p>
<p><strong>问题的关键在于</strong>：<strong>我给你的ack是不可靠的，需要你给我的ack回复一个ack，同样的道理。你给我的ack也不可靠，我也需要再给你的ack回复一个ack。</strong></p>
<p>TCP连接建立中也没有好的办法解决这个问题。因此，client发送完Fin，并接受Ack后就会关闭自己这一侧的连接，但是服务器并不知道client是否关闭了，因此还可以往client发送数据，所以client要设置成这个时候可以接收数据，但是不能发送数据（除了Ack）。</p>
<p>服务器发送完Fin，接收到Ack后，关闭自己这一侧的连接，此时服务器也是不能发送数据（除了Ack），只能接收数据。</p>
<p>双方其实都不知道对方是否关闭了连接，只能够知道自己关闭了连接。那么客户端在接收到服务器的Fin之后，回一个Ack，并且不知道Ack是否能够到达，因此会等待一段时间，如果这段时间内没有再收到数据或者Fin，就会关闭连接。</p>
<p>服务器因为可以接收到Ack所以接收到之后就会关闭连接。</p>
<h1 id="拥塞控制原理">6. 拥塞控制原理</h1>
<p>拥塞，没有一个官方的定义：太多的数据需要网络传输，超过了网络的处理能力。</p>
<p>拥塞控制与流量控制不同，流量控制是端到端之间的，而拥塞控制是网络的。</p>
<p>拥塞的表现：</p>
<ul>
<li>分组丢失：路由器缓冲区溢出</li>
<li>分组经理比较长的延迟：在路由器中的队列排队</li>
</ul>
<p>拥塞控制是网络 Top10 问题。</p>
<h2 id="拥塞的原因代价">6.1. 拥塞的原因/代价</h2>
<p>为了更好的说明拥塞，引入以下几个场景</p>
<h3 id="场景1">6.1.1. 场景1</h3>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604135804.png" /></p>
<p>如上图，2个发送端，2个接收端。一个路由器具备无限大的缓冲。发送端到路由器的输出链路带宽为R。并且没有重传（分组不会丢失，就没必要重传）</p>
<p>此时，数据往网络中传入分组的速度 <span class="math inline">\(\lambda_{in}\)</span> 以及分组从网络中出来，到达接收到的速度 <span class="math inline">\(\lambda_{out}\)</span> 的关系如下所示：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604140043.png" /></p>
<p>当 <span class="math inline">\(\lambda_{in}\)</span> 没到达 R/2 时，某一时间段，向网络中传入多少分组，网络就会输出多少分组。但是，一旦 <span class="math inline">\(\lambda_{in}\)</span> 达到并且超过 R/2 时，无论像网络中传入多少分组，网络只能输出 R/2 的分组，因为这到达链路的上限了。</p>
<p>这种情况下，网络延迟和 <span class="math inline">\(\lambda_{in}\)</span> 的关系如下：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604140312.png" /></p>
<h3 id="场景2">6.1.2. 场景2</h3>
<p>这种情况下，路由器缓冲队列有限，发送端知道路由器的缓冲区有没有空间</p>
<ul>
<li>只在缓冲区可用的时候发送</li>
<li>分组不会丢失：<span class="math inline">\(\lambda^{&#39;}_{in} = \lambda_{in}\)</span></li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604142205.png" /></p>
<p>这种情况下就很简单了</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604142348.png" /></p>
<p>该场景下，网络延迟也不算高，取决于路由器的缓冲队列的长度。</p>
<h3 id="场景3">6.1.3. 场景3</h3>
<p>与场景2类似，不过这时候不知道路由器缓冲区信息，但是<strong>明确知道分组是否丢失</strong>（任何时刻只要分组丢失，发送端都能知道）</p>
<ul>
<li>分组丢失时，发送端重传</li>
<li>分组会丢失，所以 <span class="math inline">\(\lambda^{&#39;}_{in} = \lambda_{in}\)</span></li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604142828.png" /></p>
<p>这种情况下，<span class="math inline">\(\lambda^{&#39;}_{in}\)</span> 和 <span class="math inline">\(\lambda_{out}\)</span> 的关系如下：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604142916.png" /></p>
<p>这是因为，当分组传入网络的速度小时，路由器还能服务的过来，缓冲区不满，此时分组不会丢失，因此早期的时候还是接近于1比1的关系。</p>
<p>但是当分组传入的速度达到一定程度的时候，路由器服务不来了，缓冲区逐渐被填满，当再来分组时只能被丢弃，这时候可能传入100的分组，但是出来时只有80个，20个被丢弃了。</p>
<p>如果需要达到100的吞吐量，那么发送方就需要往网络传入140甚至更多的分组，40都是重传的。</p>
<p>现实情况与这非常的像，不过有一点不一样，那就是现实中并不知道分组是否丢失（可能是个倒霉蛋，每次都在路由器队列的最后一个），超时定时器一到，就会重传。此时，网络中就有可能存在一个或多个同样的分组。但是 <span class="math inline">\(\lambda^{&#39;}_{in}\)</span> 和 <span class="math inline">\(\lambda_{out}\)</span> 关系图还是一样的。</p>
<h3 id="场景4">6.1.4. 场景4</h3>
<p>这是网络中最坏的一种情况</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604143647.png" /></p>
<p>解释一下：</p>
<ul>
<li>A发送给D的分组经过2，3路由器</li>
<li>B发送给C的分组经过1，2路由器</li>
<li>C发送给B的分组经过3，4路由器</li>
<li>D发送给A的分组经过4，1路由器</li>
</ul>
<p>当 <span class="math inline">\(\lambda^{&#39;}_{in}\)</span> 和 <span class="math inline">\(\lambda_{in}\)</span> 增加时，会发生什么情况？</p>
<p>刚开始随着<span class="math inline">\(\lambda^{&#39;}_{in}\)</span> 和 <span class="math inline">\(\lambda_{in}\)</span> 增加，吞吐量也会增加。</p>
<p>红色的分组和蓝色的分组都需要经过2号路由器，但是红色的可以直达，而蓝色的需要经过1号路由器。<strong>当 <span class="math inline">\(\lambda^{&#39;}_{in}\)</span> 和 <span class="math inline">\(\lambda_{in}\)</span> 增加，使网络会非常拥塞时，每个路由器的缓冲区一般都处于满的状态，有时候会空出一个位置，又立马被其他分组给填入</strong>。</p>
<p>这种情况下，2号路由器空出的位置会被哪个颜色的分组给占有呢？答案是红色，因为红色从主机出来直接就到了2号速度较快，而蓝色需要经过1号再到达2号，速度较慢。因此蓝色分组会在红色分组到达2号路由器之后到达，此时路由器缓冲区已满，蓝色分组被丢弃。</p>
<p>其他路由器也是一样的。3号路由器是红色和绿色共用，但是红色到达3号时会被丢弃。4号路由器又绿色和粉色公用，绿色到达4号时会被丢弃。1号路由器由粉色和蓝色公用，粉色到达1号时会被丢弃。</p>
<p>这种情况下，所有路由器死锁。即使4个发送方疯狂的往网络里传入数据，也没有一个数据可以从网络中出来。吞吐量为0，此时<span class="math inline">\(\lambda^{&#39;}_{in}\)</span> 和 <span class="math inline">\(\lambda_{out}\)</span> 的关系如下：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604144605.png" /></p>
<p>因此，从上述4个场景总结出拥塞的代价有：</p>
<ul>
<li>为了达到一个有效输出，网络需要做更多工作（重传）</li>
<li>没有必要的重传，使得链路中存在多个同一分组的copy，降低了有效输出率</li>
<li>当分组丢失时，任何“关于这个分组的上游传输能力”都被浪费</li>
</ul>
<blockquote>
<p>上游传输能力：以场景4中红色分组为例，红色分组在3号路由器被丢弃，但是此时它已经经过了2号路由器，此时被丢弃，那么在2号路由器中排队的时间都被浪费，这就是上有传输能力被浪费的意思。这在网络拥塞的时候是很可惜的。</p>
</blockquote>
<h2 id="拥塞控制的方法">6.2. 拥塞控制的方法</h2>
<p>有两种拥塞控制的方法</p>
<ol type="1">
<li><strong>端到端的拥塞控制</strong>
<ul>
<li>没有来自网络的显式反馈</li>
<li>端系统根据延迟和丢失时间推断是否拥塞</li>
<li>TCP采用该方法（TCP根据超时重传、收到3个冗余的Ack来判断网络拥塞以降低发送速率）</li>
</ul></li>
<li><strong>网络辅助的拥塞控制</strong>
<ul>
<li>路由器提供给端系统反馈信息
<ul>
<li>设置bit位，显示是否有拥塞</li>
<li>显示提供发送端可以采用的速率</li>
</ul></li>
</ul></li>
</ol>
<p>TCP采用的比较好理解，如果发送端超时重传，或者收到3个冗余的Ack，说明之前发送的分组对方没有收到，有理由的怀疑网络可能出现了拥塞。</p>
<p>举一个ATM ABR的拥塞控制了解第二种办法</p>
<p><strong>Asynchronous Transfer Mode(ATM)中</strong>：</p>
<ul>
<li>发送的是信元，固定为53字节，5字节的头部和48字节的数据
<ul>
<li>资源管理信息RM cell</li>
<li>数据心愿 data cell</li>
</ul></li>
<li>发送端发送data cell的时候，会将RM cell有间隔的插入data cell中</li>
<li>RM cell中有三个bit信息，可以被交换机、路由器设置（<strong>网络辅助</strong>）
<ul>
<li>NI bit: no increase in rate（轻微拥塞）速率不要增加了</li>
<li>CI bit: congestion indication 拥塞指示</li>
<li>ER: explicit rate 当前经过的链路的最小带宽（两个bit）</li>
</ul></li>
<li>接收到接收到RM cell不做任何修改，直接返回给发送端</li>
</ul>
<p><strong>Available Bit Rate(ABR)</strong>：</p>
<ul>
<li>如果发送端的路径轻载，发送方可以使用整个带宽，或者有时候超过一点也没问题的速率发送</li>
<li>如果发送端路径拥塞，发送方限制其发送的速度到一个最小保障的速率上</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604150112.png" /></p>
<p>RM cell每经过一个路由器，该路由器就会设置NI, CI, ER，如果网络有一点拥塞，将NI置1；如果网络已经很拥塞了，将CI置1；</p>
<p>路由器还会修改ER，如果它的发送带宽是100，但是ER的值被其他路由器修改了，比如说当前是150，那么该路由器会将ER的值改为100；如果ER的值当前是70，那么该路由器就不会修改ER的值。因此，当RM cell从发送端出发，到达接收端再返回到发送端，发送端就能够知道网络是否拥塞（NI, CI），并且能够知道上一次网络路径中的最小链路的带宽。</p>
<h1 id="tcp拥塞控制">7. TCP拥塞控制</h1>
<p>虽然拥塞控制的方法2的效果会比较好，但是网络核心的路由器的负担会加重，不符合网络核心简单的TCP/IP架构原则。所以<strong>TCP采用端到端的拥塞控制机制</strong>。</p>
<blockquote>
<p>TCP/IP架构原则：网络核心简单；复杂的功能放在网络边缘（传输层及以上）实现</p>
</blockquote>
<p>接下来需要解决拥塞控制的两个比较大的问题：</p>
<ol type="1">
<li>发送方如何检测拥塞</li>
<li>控制策略：检测到拥塞之后该怎么办</li>
</ol>
<h2 id="拥塞感知">7.1. 拥塞感知</h2>
<p>主要将网络拥塞分为两类：</p>
<ol type="1">
<li>网络拥塞</li>
<li>轻微拥塞</li>
</ol>
<p>之前也提到过，可以通过<strong>分组丢失</strong>或者<strong>3个冗余的Ack</strong>来判断网络是否拥塞。</p>
<p><strong>一旦分组丢失，发送方就会认为网络拥塞</strong>，分组丢失也有两个原因：</p>
<ol type="1">
<li>原因1：网络拥塞（某个路由器的缓冲区满，分组被丢弃），<strong>概率大</strong></li>
<li>原因2：出错被丢弃（各种出错，比如比特错误），<strong>概率小</strong>。如果是物理连接，不是Wi-Fi，则概率更小了</li>
</ol>
<p>不论什么原因，这都会导致超时时间到达，但是ack没有到达。<strong>一旦超时，发送方就会认为网络拥塞了</strong>。虽然有一定的误判，比如说原因2并不是网络拥塞，此时网络可能不拥塞，但也是会被发送方认为拥塞。但是总体的控制方向是对的，小概率的误判不会影响整体的性能。</p>
<p><strong>3个冗余的Ack则发送方认为网络轻微拥塞</strong>。解释可以看下图，比较好理解。ack都能到来这么多次，说明拥塞不严重嘛。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604182606.png" /></p>
<h2 id="控制策略">7.2. 控制策略</h2>
<blockquote>
<p>下面提到的CongWin/2指的是上次CongWin/2的值作为这次CongWin的阈值(ssthresh)</p>
</blockquote>
<p>如果检测到拥塞或者轻微拥塞，发送方需要控制发送的速率：</p>
<ul>
<li><p>维持一个拥塞窗口的值：CongWin</p></li>
<li><p>发送端限制<strong>已发送但是未确认</strong>的数据量的上限，即发送窗口要小于CongWin：</p>
<p><span class="math inline">\(LastByteSent-LastByteAcked \leq CongWin\)</span></p></li>
</ul>
<p>根据上面两点，粗略的控制发送方往网络中注入的速率。</p>
<p><span class="math display">\[
rate \approx \frac {CongWin}{RTT} B/s
\]</span></p>
<p>那么具体是如何操作的呢？首先，CongWin是动态的，是感知到网络拥塞程度的函数。</p>
<ul>
<li>超时或者3个冗余的Ack，此时 CongWin 应该 ⬇&gt;，但是处理还是不同的：
<ul>
<li><strong>超时</strong>：CongWin降为1MSS，进入SS(slow-start)阶段，然后再倍增到 CongWin/2（每个RTT，CongWin翻倍，但不能超过CongWin/2），从而进入CA(Congestion Avoidance)阶段</li>
<li><strong>3个冗余的Ack</strong>：CongWin 降为 CongWin/2，直接进入CA阶段</li>
</ul></li>
<li>既没有超时，也没有3个冗余的Ack，CongWin 应该 ⬆，分为两个阶段：
<ul>
<li><strong>SS阶段</strong>：指数增加（每个RTT）</li>
<li><strong>CA阶段</strong>：加性增加（每个RTT）</li>
</ul></li>
</ul>
<p>这是对CongWin的控制，同时还需要控制发送窗口不能太大，否则即使速率慢下来了，还是会往网络中注入很多的数据。对发送窗口的控制采取联合控制的方法：</p>
<ul>
<li>发送端控制<strong>发送但是未确认的</strong>数据量同时也不能够超过接收窗口，满足流量控制要求</li>
<li><span class="math inline">\(sendWin = min(CongWin, RecvWin)\)</span></li>
<li>这样的控制方法同时满足<strong>流量控制</strong>和<strong>拥塞控制</strong></li>
</ul>
<p>总结一下拥塞控制策略：</p>
<ol type="1">
<li>慢启动(slow start, SS)</li>
<li>拥塞避免(congestion avoidance, CA)：AIMD(Additive-Increase, Multiplicative-Decrease)：加性增、乘性减少</li>
<li>超时后的保守策略（CongWin降为1MSS）</li>
</ol>
<h3 id="慢启动阶段">7.2.1. 慢启动阶段</h3>
<p><strong>重要判断依据：CongWin &lt; ssthresh</strong></p>
<p>连接刚建立的时候，CongWin = 1MSS。接着进行指数性增加，知道检测到拥塞</p>
<ul>
<li>启动初值很低</li>
<li>但是速度很快</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604184512.png" /></p>
<p>如上图：</p>
<ul>
<li>刚开始的时候，CongWin为1，发送一个segment，RTT之后收到一个ack，此时CongWin翻倍，变为2</li>
<li>发送2个segment，一个RTT之后，收到1个Ack（这个Ack是对两个segment的确认，或者说收到2个Ack），此时CongWin再次翻倍，变为4</li>
<li>发送4个segment，一个RTT之后，收到1个Ack（对4个segment的确认），CongWin变为8</li>
<li>....</li>
</ul>
<p>所以慢启动的特点有：</p>
<ol type="1">
<li>每一个RTT，CongWin翻倍</li>
<li>每收到一个报文的Ack，CongWin加1（与第一个特点等价，CongWin为多少，一个RTT内就会收到多少个segment的Ack）</li>
<li>只要不超时或者收到3个冗余的Ack，CongWin每个RTT都会翻倍</li>
</ol>
<p>总结：慢启动初始速率很慢（1MSS），但是加速度很快，是指数性的。极短时间内就能增加到 CongWin/2 的值，因此后面的计算会将SS忽略不计。</p>
<p>不论是慢启动阶段还是拥塞避免阶段，只要发生了<strong>分组丢失</strong>，就会执行两件事：</p>
<ol type="1">
<li>ssthresh = CongWin/2</li>
<li>CongWin = 1 MSS</li>
</ol>
<p>然后进入慢启动阶段。</p>
<h3 id="拥塞避免阶段">7.2.2. 拥塞避免阶段</h3>
<p><strong>重要判断依据：CongWin &gt;= ssthresh</strong></p>
<p>当慢启动达到阈值时，也就是 CongWin = ssthresh 时，进入拥塞避免阶段。该阶段有3个特点：</p>
<ul>
<li><strong>加性增</strong>：当 CongWin = ssthresh 后，一个RTT内没有发生<strong>分组丢失</strong>或者收到<strong>3个冗余的Ack</strong>，将CongWin加上1个MSS；</li>
<li><strong>乘性减</strong>：当 CongWin = ssthresh 后，一个RTT内发生了<strong>3个冗余的Ack</strong>，ssthresh=CongWin/2, CongWin=sshtresh+3</li>
</ul>
<p>长期来看就是长这样：</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604190419.png" /></p>
<p>（忽略掉了慢启动过程）</p>
<h3 id="两个阶段具体实现">7.2.3. 两个阶段具体实现</h3>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604190756.png" /></p>
<p>解释（蓝色）：在这之前，CongWin=16MSS的时候，发生了超时，因此，ssthresh=16/2=8，CongWin = 1。将其分为4个阶段</p>
<ol type="1">
<li>SS阶段，每个RTT内没有感知到拥塞，因此翻倍增加，直到 CongWin=ssthresh。之后进入CA</li>
<li>CA阶段，每个RTT内没有感知到拥塞，因此每次加1，直到发生了超时，ssthresh = CongWin/2=6, CongWin=1。再次进入到SS阶段</li>
<li>还是SS阶段，需要注意的是4之后变成6，这里不再翻倍是因为ssthresh为6，SS阶段的CongWin只能 <span class="math inline">\(\leq\)</span> ssthresh</li>
<li>再次进入到CA阶段</li>
</ol>
<p>这里其实少了一种情况，假设第4阶段到达 CongWin=10时发生了3个冗余的Ack，那么ssthresh=CongWin/2=5，CongWin=ssthresh+3=8，直接进入CA阶段</p>
<h3 id="总结-1">7.2.4. 总结</h3>
<ol type="1">
<li>当 CongWin &lt; ssthresh 时，发送端处于SS阶段，窗口指数性增长</li>
<li>当 CongWin &gt;= ssthresh 时，发生端处于CA阶段，窗口加性增长</li>
<li>当收到3个冗余的Ack时，ssthresh=CongWin/2, CongWin=ssthresh+3</li>
<li>当超时事件发生时，ssthresh=CongWin/2, CongWin=1，进入SS阶段</li>
</ol>
<h2 id="tcp吞吐量">7.3. TCP吞吐量</h2>
<p>忽略慢启动阶段，假设发送端总有数据传输。W为发生丢失事件时的窗口尺寸</p>
<p><span class="math display">\[平均窗口尺寸 = (\frac w2 + w)/2 = \frac 34w\]</span></p>
<p><span class="math display">\[平均吞吐量 = \frac {3w}{4RTT}\]</span></p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604193208.png" /></p>
<h2 id="tcp公平性">7.4. TCP公平性</h2>
<p><strong>目标：如果K个TCP连接分享一个带宽为R的链路，每一个会话的有效带宽为 R/K</strong></p>
<p>简化以下，假设k为2，R为10</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604193323.png" /></p>
<p>上图的模型，可以画出下图的坐标示意图，其中，x轴为TCP连接1的注入网络的速率（数据包的量），y轴为TCP连接2的注入网络的速率（数据包的量）。</p>
<p><img src="https://raw.githubusercontent.com/hdfzzf/Figurebed/main/imgs/20220604194723.png" /></p>
<p>解释一下：</p>
<ul>
<li>假设最开始的时候很不公平，从E点开始，此时TCP1占用5，TCP2占用1，然后线性增加到达F，TCP1占用6，TCP2占用2，依此类推，到达H点，TCP1占用8，TCP2占用4，此时已经两者之后超过了10，但这是可以做得到的，因为网络会有时延的，G点虽然占用了正好的10，但这个时候可能还没收到拥塞感知的消息，因此继续加到H，收到了拥塞感知，那么需要减半，到达I点</li>
<li>同样的过程I一直增加到M点，然后继续减半到N</li>
<li>N也是一样到P点，然后减半到Q</li>
<li>Q也是继续增加，这里没画完</li>
</ul>
<p>可以看到，整个过程两个TCP连接的注入网络的速率越来越逼近 y=x 那条线，也就是两个连接发送数据的量越来越趋近于相等。也就是两个TCP连接占用链路的带宽也趋近于相等。因此，会越来越公平。</p>
<p><strong>结论：长期来看，TCP是具有公平性的</strong></p>
<p>作为对比，UDP就不具有公平性。UDP不管拥塞，也不管发的太快对方能否接收，只要有数据就一直发。假设数据一直有，那么先进行UDP数据发送的占用链路的大部分资源，后进行的占用少部分资源。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag"># 计算机网络</a>
              <a href="/tags/%E8%AE%A1%E7%AE%97%E7%BD%91%E7%BB%9C%E6%95%99%E7%A8%8B-%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/" rel="tag"># 计算网络教程 自顶向下方法</a>
              <a href="/tags/B%E7%AB%99%E4%B8%AD%E7%A7%91%E5%A4%A7%E8%AE%A1%E7%BD%91/" rel="tag"># B站中科大计网</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/06/02/%E7%AC%AC2%E7%AB%A0%20%E5%BA%94%E7%94%A8%E5%B1%82/" rel="prev" title="第2章 应用层">
                  <i class="fa fa-chevron-left"></i> 第2章 应用层
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/06/05/%E7%AC%AC4%E7%AB%A0%20%E7%BD%91%E7%BB%9C%E5%B1%82%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%B9%B3%E9%9D%A2/" rel="next" title="第4章 网络层：数据平面">
                  第4章 网络层：数据平面 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hdfzzf</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">534k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">8:05</span>
  </span>
</div>
<div class="busuanzi-count">
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"hdfzzf","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
